{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Intelligence (ConvAI) Challenge Human-Bot Data Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Datasource**: The human-bot chats stored as json files are downloaded from here: http://convai.io/data/\n",
    "The datasets are generated as part of Conversational Intelligence (ConvAI) Challenge done under the scope of NIPS 2017 Competitions track.\n",
    "        \n",
    "**Output**: The **json file contains numerous one-to-one dialogues. We need to extract the conversation from each dialogue and mark both participants with different symbols per line.** The conversation data after extraction is encoded and fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines permissible characters for the chatbot\n",
    "\n",
    "alphas = 'abcdefghijklmnopqrstuvwxyz1234567890 .,?'\n",
    "alphas = alphas + alphas.upper()\n",
    "\n",
    "def permissible_chars(word):\n",
    "\n",
    "    for char in word:\n",
    "        if char in alphas:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters. \n",
    "\n",
    "# CHANGE the File name to process different files. We have only 3\n",
    "file_name = \"data_intermediate\"\n",
    "\n",
    "infile = open(\"json/\"+file_name+\".json\", \"r\")\n",
    "outfile = open(\"data/\"+file_name+\".yml\", \"w\")\n",
    "\n",
    "# Get the JSON data.\n",
    "json_parsed = json.loads(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the parsed json data to get 'text' tag from dialogue\n",
    "# This represents the conversation between 2 parties involved in dialogue\n",
    "chat= \"\"\n",
    "for i in range(0, len(json_parsed)):\n",
    "    \n",
    "\tdialog = json_parsed[i].get('dialog')\n",
    "\tfor j in range(0, len(dialog)):\n",
    "\n",
    "\t\ttext = dialog[j].get('text')\n",
    "\n",
    "\t\t# From the data it is known that \"End\" is used as stop word \n",
    "\t\t# for each dialogue or conversation between two people.\n",
    "\t\t# Stop the iteration if the word \"End\" is found.\n",
    "\t\tif (text.find('end') != -1 or text.find('End') != -1):\n",
    "\t\t\tbreak\n",
    "\t\tif (text == 'start'):\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# remove all tokens that are not alphabetic\n",
    "\t\twords = [w for w in text if permissible_chars(w)]\n",
    "\t\tconversation = ''.join(word[0] for word in words)\n",
    "        \n",
    "        # mark each participant with some symbol.\n",
    "\t\t# alternate b/w question and answer\n",
    "\t\tif j % 2 == 0:\n",
    "\t\t\tchat += \"- - \"\n",
    "\t\telse:\n",
    "\t\t\tchat += \"  - \"\n",
    "\n",
    "\t\tchat +=  conversation + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output files as yml files.\n",
    "# print(chat)\n",
    "outfile.write(chat)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
